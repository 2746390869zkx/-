### 1、Redis常见的五种数据类型

下面是 Redis 常见的五种数据类型，以及它们的底层实现和使用场景的简要分析和比较：

| 数据类型   | 底层实现                                                 | 使用场景                                                     |
| ---------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| String     | 内部使用**字符串**表示，支持多种操作                     | 常用于存储单个值，比如计数器、缓存、用户信息等等             |
| List       | 内部使用**双向链表**表示，支持插入、删除等操作           | 常用于存储有序的数据，比如消息队列、任务队列等等             |
| Set        | 内部使用**哈希表**表示，支持集合运算（交集、并集、差集） | 常用于存储唯一的、无序的数据，比如好友列表、标签列表等等     |
| Hash       | 内部使用**哈希表**表示，支持存储多个键值对               | 常用于存储一个对象的多个属性，比如用户信息、商品信息等等     |
| Sorted Set | 内部使用**跳表**和**哈希表**表示，支持按照分数排序       | 常用于存储有序的数据，并且需要按照分数排序，比如排行榜、计分系统等等 |

在使用 Redis 的时候，需要根据实际需求选择不同的数据类型，以便实现最优的性能和效果。下面是对每种数据类型的更详细的分析和比较：

1. String 类型

String 类型是 Redis 最基本的数据类型，Redis 内部使用字符串表示，支持多种操作，比如赋值、获取、增加、减少等等。在底层实现上，Redis 使用简单动态字符串（SDS）来表示字符串，SDS 是一种 C 语言的字符串表示方式，它可以自动扩容，并且支持二进制安全。

使用 String 类型的场景很广泛，比如存储单个值，比如计数器、缓存、用户信息等等。

2. List 类型

List 类型是 Redis 中的一个有序列表，内部使用双向链表来表示，支持插入、删除等操作。List 类型支持从两端插入和删除元素，可以使用 LPush、RPush、LPop、RPop 等命令进行操作。

使用 List 类型的场景比较明显，它常用于存储有序的数据，比如消息队列、任务队列等等。

3. Set 类型

Set 类型是 Redis 中的一个无序集合，内部使用哈希表来表示，支持集合运算（交集、并集、差集）。Set 类型支持添加、删除、判断元素是否存在等操作，可以使用 SAdd、SRem、SMembers、SIsMember 等命令进行操作。

使用 Set 类型的场景也比较明显，它常用于存储唯一的、无序的数据，比如好友列表、标签列表等等。

4. Hash 类型

Hash 类型是 Redis 中的一个哈希表，内部使用哈希表来表示，支持存储多个键值对。Hash 类型支持添加、删除、获取、判断元素是否存在等操作，可以使用 HSet、HGet、HDel、HExists 等命令进行操作。

使用 Hash 类型的场景比较明显，它常用于存储一个对象的多个属性，比如用户信息、商品信息等等。

5. Sorted Set 类型

Sorted Set 类型是 Redis 中的一个有序集合，内部使用跳表和哈希表来表示，支持按照分数排序。Sorted Set 类型支持添加、删除、获取、按照分数范围获取等操作，可以使用 ZAdd、ZRem、ZRangeByScore 等命令进行操作。

使用 Sorted Set 类型的场景也比较明显，它常用于存储有序的数据，并且需要按照分数排序，比如排行榜、计分系统等等。

综上所述，Redis 提供了多种数据类型来满足不同的需求，选择合适的数据类型可以大大提高 Redis 的性能和效果。在实际使用中，需要根据具体的场景和需求来选择合适的数据类型。

Redis 常见的五种数据类型是：字符串（string）、哈希（hash）、列表（list）、集合（set）和有序集合（sorted set）。

他们的**使用场景**分别为：

- 字符串（string）：用来存储字符串或二进制数据，例如用户的 session 数据、缓存数据等。
- 哈希（hash）：用于存储对象，可以将对象的属性和对应的值存储在一个 hash 类型中，例如用户对象、商品对象等。
- 列表（list）：用于存储列表数据，例如微博的关注列表、粉丝列表等。
- 集合（set）：用于存储无序、不重复的数据集合，例如微博的点赞用户列表、在线用户列表等。
- 有序集合（sorted set）：用于存储有序、不重复的数据集合，例如排行榜、热门商品列表等。

下面是这些数据类型的代码实现示例：

- 字符串（string）：

```
# 设置键值对
SET key value

# 获取值
GET key
```

- 哈希（hash）：

```
# 设置哈希值
HSET key field value

# 获取哈希值
HGET key field
```

- 列表（list）：

```
# 在列表尾部添加元素
RPUSH key value

# 获取列表元素
LRANGE key start stop
```

- 集合（set）：

```
# 添加元素
SADD key member

# 获取元素
SMEMBERS key
```

- 有序集合（sorted set）：

```
# 添加元素和分数
ZADD key score member

# 获取元素
ZRANGE key start stop
```



### 2、新增的物种数据类型

1. **BitMap（2.2 版新增）**

使用场景：
BitMap 主要用于大规模数据的去重和判重，可以节约大量存储空间和计算时间。例如，可以利用 BitMap 判定一个 IP 地址是否已经访问过某个网站，以及某个用户是否已经购买过某个商品等。

底层实现：
BitMap 底层实现是一个由 0 和 1 组成的数组，每个元素代表一个二进制位。当某个元素的值为 1 时，表示对应的元素已经出现过，否则表示未出现过。BitMap 主要支持两种操作：插入和查询。插入操作将指定的元素位置置为 1，查询操作则判断指定元素位置的值是否为 1。

2. **HyperLogLog（2.8 版新增）**

使用场景：
HyperLogLog 主要用于对大规模数据进行基数（distinct count）估计，可以快速、准确地估计一个数据集合的基数。例如，可以利用 HyperLogLog 估计某个网站的日活跃用户数、某个应用程序的安装量等。

底层实现：
HyperLogLog 的底层实现是基于哈希函数和概率统计的算法。具体来说，HyperLogLog 会对输入的数据进行哈希映射，将数据映射到一个固定长度的二进制串中。然后，根据二进制串中前缀 0 的数量来估算数据集合的基数。HyperLogLog 算法的精度主要取决于哈希函数的质量和哈希值的长度。

3. **GEO（3.2 版新增）**

使用场景：
GEO 主要用于地理位置信息的存储和查询，可以帮助开发者实现各种基于地理位置的应用。例如，可以利用 GEO 存储用户的位置信息，然后根据距离等因素推荐附近的商家、朋友等。

底层实现：
GEO 的底层实现是基于 zset（有序集合）的数据结构，每个元素代表一个地理位置。zset 中的元素按照距离值从小到大排序，可以通过指定一个中心点和半径来查询符合条件的元素。GEO 还支持计算两个位置之间的距离和方位角等操作。

4. **Stream（5.0 版新增）**

使用场景：
Stream 主要用于高吞吐量的消息队列和事件流处理，可以支持实时数据的处理和分析。例如，可以利用 Stream 实现实时日志处理、实时数据采集、实时监控等。

底层实现：
Stream 的底层实现是基于 Redis 的数据结构和命令扩展实现的。Stream 中的数据被组织为一个有序的消息序列，每个消息包含一个唯一的 ID 和一个关联的数据项。Stream 支持多个消费者并发消费消息，可以通过指定消费者组来实现负载均衡和容错。Stream 还支持消息的持久化和恢复，可以保证消息的可靠性和一致性。



### 3、AOF 持久化是怎么实现的？

AOF（Append Only File）是 Redis 中的一种持久化方式，它将 Redis 所有修改数据的命令写入一个日志文件中，以保证数据的持久化。

##### AOF 持久化的过程如下：

1. Redis 接收到一个写命令。
2. Redis 将这个命令追加到 AOF 文件的末尾。
3. Redis 将这个命令执行，修改内存中的数据。
4. Redis 等待操作系统将 AOF 文件写入磁盘。
5. 完成持久化。

在 Redis 运行过程中，会不断地将修改数据的命令追加到 AOF 文件中。当 Redis 重启时，会读取 AOF 文件的内容，并执行其中的命令，来恢复数据。

需要注意的是，在 AOF 持久化的过程中，会产生大量的磁盘 IO 操作，会对 Redis 的性能产生一定的影响。因此，在高并发的场景下，可以考虑使用 Redis 的 RDB 持久化方式，它会在一个时间点将内存中的数据快照写入磁盘，具有更高的性能。但是，AOF 持久化相对来说更加可靠，可以在数据丢失的情况下更好地保证数据的完整性。



##### 存在一些风险的场景，主要包括以下几种：

1. 磁盘空间不足：AOF 文件会一直追加写入操作，如果磁盘空间不足，可能会导致 Redis 无法正常工作。

2. 写入速度过慢：如果 Redis 的写入速度过快，而 AOF 文件的写入速度跟不上，可能会导致 Redis 的响应速度变慢。

3. AOF 文件损坏：如果 AOF 文件损坏，可能会导致 Redis 无法正常工作。AOF 文件损坏的原因可能是磁盘故障、文件系统错误、操作系统错误等。

4. AOF 重写期间出现故障：在进行 AOF 重写时，Redis 会创建一个新的 AOF 文件，将原来的 AOF 文件重写成新的 AOF 文件。如果在重写期间出现故障，可能会导致数据丢失或者数据不一致的问题。

为了避免这些风险，我们可以采取以下几种措施：

1. 定期备份 AOF 文件，以防止数据丢失。

2. 监控磁盘空间和 AOF 文件的写入速度，并及时进行扩容或优化。

3. 定期进行 AOF 文件的重写，以减小 AOF 文件的大小。

4. 在进行 AOF 文件重写时，采用后台进行的方式，避免影响 Redis 的正常工作。

##### **写回策略**

在 AOF 持久化中，有三种不同的写回策略，分别是：

1. 每个命令都立即写入磁盘。
2. 每秒钟写入一次磁盘。
3. 当 AOF 文件大小达到一定阈值时，执行一次写入磁盘操作。

不同的写回策略会对 Redis 的性能和数据的安全性产生不同的影响。

1. 每个命令都立即写入磁盘

这种写回策略可以保证数据的完整性和安全性，但是会对 Redis 的性能产生较大的影响。因为每个命令都需要等待磁盘 IO 操作完成后才能执行下一个命令，导致 Redis 的性能受到瓶颈限制。同时，频繁的磁盘 IO 操作也会增加磁盘的负载，降低系统的稳定性。

2. 每秒钟写入一次磁盘

这种写回策略可以在一定程度上保证数据的安全性，同时又不会对 Redis 的性能产生过大的影响。但是如果 Redis 重启或崩溃，最多会丢失一秒钟的数据。因此，这种策略适合对数据安全性要求不是特别高的场景。

3. 当 AOF 文件大小达到一定阈值时，执行一次写入磁盘操作

这种写回策略是性能和安全性的一个折中方案，可以在一定程度上保证数据的安全性，同时不会对 Redis 的性能产生过大的影响。但是，如果 Redis 重启或崩溃，可能会丢失最后一次写入磁盘之后的一部分数据。因此，这种策略适合对数据安全性要求不是特别高的场景。

综上所述，不同的写回策略适用于不同的场景。如果对数据安全性要求非常高，可以选择每个命令都立即写入磁盘的策略；如果对数据安全性要求不是特别高，但是对性能要求比较高，可以选择每秒钟写入一次磁盘的策略；如果对数据安全性和性能都有一定要求，可以选择当 AOF 文件大小达到一定阈值时，执行一次写入磁盘操作的策略。



##### **AOF的写入过程**

1. Redis 执行完写操作命令后，会将命令追加到 `server.aof_buf` 缓冲区；
2. 然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；
3. 具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。



##### AOF的重写过程

AOF重写机制是Redis为了解决AOF文件过大而引入的一种机制。它可以在不中断Redis服务的情况下，将AOF日志文件中的命令序列压缩并重写为一份新的AOF文件，从而达到减小AOF文件大小的目的。

**AOF重写的过程如下：**

1. **Redis会fork一个子进程来进行AOF重写操作，父进程继续接收命令请求并将其写入AOF缓冲区中。**
2. **子进程会遍历Redis中的所有数据，并将其转换为一系列命令序列。**
3. **子进程将这些命令序列写入到一个新的AOF文件中，并将该文件重命名为原来的AOF文件。**
4. **父进程继续将新的命令序列写入到AOF缓冲区中，直到新的AOF文件中包含了父进程接收到的所有命令。**
5. **父进程将缓冲区中未被写入到新AOF文件的命令序列写入到新AOF文件中。**

**AOF重写机制的问题主要有两方面：**

1. AOF重写操作会占用比较多的CPU和内存资源，可能会导致Redis在重写期间性能下降。
2. 在AOF重写期间，如果有新的写命令进来，那么这些命令不会被写入到新的AOF文件中，而是仍然写入到原来的AOF文件中，这可能会导致AOF文件的大小并没有减小，反而变得更大了。

为了解决这些问题，Redis引入了增量式AOF重写机制，它可以在不停止Redis服务的情况下，实现AOF文件的增量更新。具体来说，增量式AOF重写机制会在AOF重写期间，将新的写命令同时写入到新的AOF文件和原来的AOF文件中，这样可以避免新的写命令丢失的问题。同时，增量式AOF重写机制还可以将AOF重写操作分成多个小操作，以避免对Redis性能的影响。

**BGREWRITEAOF命令**

`BGREWRITEAOF` 是 Redis 的一个命令，用于在后台异步执行 AOF（Append Only File） 重写操作。它的好处主要有以下几点：

1. 减少主线程的阻塞时间：在 Redis 的 AOF 重写过程中，主线程需要遍历整个数据集来创建新的 AOF 文件。如果数据集很大，这个过程可能会占用很长时间，导致主线程被阻塞。使用 `BGREWRITEAOF` 命令可以将 AOF 重写操作放在后台执行，减少主线程的阻塞时间，提高 Redis 的性能和稳定性。

2. 降低系统负载：在 AOF 重写期间，Redis 会创建一个临时文件来存储新的 AOF 文件。如果数据集很大，这个临时文件可能会很大，导致系统负载增加。使用 `BGREWRITEAOF` 命令可以将 AOF 重写操作放在后台执行，避免对系统负载的影响。

3. 减少 AOF 文件的体积：在 Redis 的 AOF 重写过程中，Redis 会遍历整个数据集并将其中的操作写入新的 AOF 文件。由于 Redis 采用的是追加写入的方式，AOF 文件可能会变得很大。使用 `BGREWRITEAOF` 命令可以对 AOF 文件进行压缩，减少 AOF 文件的体积，提高 Redis 的性能和稳定性。

总之，`BGREWRITEAOF` 命令是 Redis 中一个非常有用的工具，可以提高 Redis 的性能和稳定性，减少系统负载。



使用写时复制技术和复制页表相关信息进行拷贝



**所以，有两个阶段会导致阻塞父进程：**

- 创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；
- 创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；

![在这里插入图片描述](D:\资料\java总资料\redis\assets\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309231944807.png)

在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。



### 4、RDB 快照是怎么实现的？



Redis 提供了两个命令来生成 RDB 文件，分别是 `save` 和 `bgsave`，他们的区别就在于是否在「主线程」里执行：

- 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程**；
- 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以**避免主线程的阻塞**；

```text
save 900 1
save 300 10
save 60 10000
```

通常可能设置至少 5 分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失 5 分钟数据。



##### RDB执行快照时，数据能被修改吗？

执行 bgsave 过程中，Redis 依然**可以继续处理操作命令**的，也就是数据是能被修改的。

那具体如何做到到呢？关键的技术就在于**写时复制技术（Copy-On-Write, COW）。**



### 5、混合持久化

Redis 4.0 提出的，该方法叫**混合使用 AOF 日志和内存快照**，也叫混合持久化

```
aof-use-rdb-preamble yes
```

在实际生产环境中，Redis 数据备份通常需要考虑以下因素：

1. 数据备份的可靠性和实时性要求：如果数据备份的可靠性和实时性要求比较高，建议使用 AOF 持久化方式，因为 AOF 持久化可以保证数据的实时性和可靠性。

2. 数据备份的存储空间要求：如果数据备份的存储空间比较紧张，建议使用 RDB 持久化方式，因为 RDB 持久化可以将 Redis 的数据快照保存到磁盘中，占用的存储空间比 AOF 持久化方式小得多。

3. 数据备份的恢复速度要求：如果数据备份的恢复速度比较重要，建议使用 RDB 持久化方式，因为 RDB 持久化方式可以将 Redis 的数据快照保存到磁盘中，恢复数据的速度比 AOF 持久化方式要快。

总的来说，选择 RDB 还是 AOF 持久化方式，需要根据实际情况进行权衡和选择。可以根据自己的业务需求，选择最适合自己的持久化方式。



### 6、如何选择RDB和AOF

在实际生产环境中，Redis 数据备份通常需要考虑以下因素：

1. 数据备份的可靠性和实时性要求：如果数据备份的可靠性和实时性要求比较高，建议使用 AOF 持久化方式，因为 AOF 持久化可以保证数据的实时性和可靠性。

2. 数据备份的存储空间要求：如果数据备份的存储空间比较紧张，建议使用 RDB 持久化方式，因为 RDB 持久化可以将 Redis 的数据快照保存到磁盘中，占用的存储空间比 AOF 持久化方式小得多。

3. 数据备份的恢复速度要求：如果数据备份的恢复速度比较重要，建议使用 RDB 持久化方式，因为 RDB 持久化方式可以将 Redis 的数据快照保存到磁盘中，恢复数据的速度比 AOF 持久化方式要快。

总的来说，选择 RDB 还是 AOF 持久化方式，需要根据实际情况进行权衡和选择。可以根据自己的业务需求，选择最适合自己的持久化方式。





### 7、Redis中的大Key问题

**大key对AOF的影响**

Redis中的AOF日志是一种持久化机制，用于将Redis中的数据保存到磁盘上。大Key会对AOF日志的写入和读取产生影响。

如果Redis中存在大Key，那么在进行AOF日志的写入时，会导致AOF文件变得非常大，因为大Key的值会被完整地写入AOF文件中，而不论其是否被修改。这会导致AOF文件的大小迅速增长，对磁盘空间的占用也会变大。

此外，在进行AOF日志的读取时，由于大Key的值较大，会导致读取AOF文件的时间变长，影响Redis的性能。因此，在使用Redis时，应该尽量避免创建大Key，以减少对AOF文件的影响。



Redis 中的大 key 指的是占用大量内存的键，比如存储了大量数据的哈希表、列表等。由于 Redis 是单线程的，一旦出现大 key，就会导致 Redis 的响应时间变慢，甚至造成 Redis 的宕机。

因此，**为了避免出现大 key，我们可以采取以下措施：**

1. **分解大 key：将一个大的键值对分解成多个小的键值对存储，这样可以减少单个键值对占用的内存空间。**

2. **使用 Redis 的数据结构：使用 Redis 提供的数据结构，例如使用 Sorted Set 替代 Hash，使用 BitMap 替代 String 等，可以大大减少内存占用。**

3. **限制键值对大小：可以通过配置 maxmemory-policy 选项限制 Redis 实例的内存使用量，或使用 Redis 的 RDB 或 AOF 持久化机制来限制键值对的大小。**

4. **分布式存储：采用 Redis 集群或者分布式存储的方式，将数据分散到多个 Redis 实例中，可以避免单个 Redis 实例出现大 key 的问题。**

总之，避免大 key 的出现是保证 Redis 服务稳定性和性能的关键之一。



#### 如何发现BigKey

##### ①redis-cli --bigkeys

利用redis-cli提供的--bigkeys参数，可以遍历分析所有key，并返回Key的整体统计信息与每个数据的Top1的big key

命令：`redis-cli -a 密码 --bigkeys`

![image-20220521133359507](D:\资料\该准备面试啦\redis\assets\image-20220521133359507.png)

##### ②scan扫描

自己编程，利用scan扫描Redis中的所有key，利用strlen、hlen等命令判断key的长度（此处不建议使用MEMORY USAGE）

![image-20220521133703245](D:\资料\该准备面试啦\redis\assets\image-20220521133703245.png)

scan 命令调用完后每次会返回2个元素，第一个是下一次迭代的光标，第一次光标会设置为0，当最后一次scan 返回的光标等于0时，表示整个scan遍历结束了，第二个返回的是List，一个匹配的key的数组

```java
import com.heima.jedis.util.JedisConnectionFactory;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.ScanResult;

import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class JedisTest {
    private Jedis jedis;

    @BeforeEach
    void setUp() {
        // 1.建立连接
        // jedis = new Jedis("192.168.150.101", 6379);
        jedis = JedisConnectionFactory.getJedis();
        // 2.设置密码
        jedis.auth("123321");
        // 3.选择库
        jedis.select(0);
    }

    final static int STR_MAX_LEN = 10 * 1024;
    final static int HASH_MAX_LEN = 500;

    @Test
    void testScan() {
        int maxLen = 0;
        long len = 0;

        String cursor = "0";
        do {
            // 扫描并获取一部分key
            ScanResult<String> result = jedis.scan(cursor);
            // 记录cursor
            cursor = result.getCursor();
            List<String> list = result.getResult();
            if (list == null || list.isEmpty()) {
                break;
            }
            // 遍历
            for (String key : list) {
                // 判断key的类型
                String type = jedis.type(key);
                switch (type) {
                    case "string":
                        len = jedis.strlen(key);
                        maxLen = STR_MAX_LEN;
                        break;
                    case "hash":
                        len = jedis.hlen(key);
                        maxLen = HASH_MAX_LEN;
                        break;
                    case "list":
                        len = jedis.llen(key);
                        maxLen = HASH_MAX_LEN;
                        break;
                    case "set":
                        len = jedis.scard(key);
                        maxLen = HASH_MAX_LEN;
                        break;
                    case "zset":
                        len = jedis.zcard(key);
                        maxLen = HASH_MAX_LEN;
                        break;
                    default:
                        break;
                }
                if (len >= maxLen) {
                    System.out.printf("Found big key : %s, type: %s, length or size: %d %n", key, type, len);
                }
            }
        } while (!cursor.equals("0"));
    }
    
    @AfterEach
    void tearDown() {
        if (jedis != null) {
            jedis.close();
        }
    }

}
```

##### ③第三方工具

- 利用第三方工具，如 Redis-Rdb-Tools 分析RDB快照文件，全面分析内存使用情况
- https://github.com/sripathikrishnan/redis-rdb-tools

##### ④网络监控

- 自定义工具，监控进出Redis的网络数据，超出预警值时主动告警
- 一般阿里云搭建的云服务器就有相关监控页面

![image-20220521140415785](D:\资料\该准备面试啦\redis\assets\image-20220521140415785.png)

#### 如何删除BigKey

BigKey内存占用较多，即便时删除这样的key也需要耗费很长时间，导致Redis主线程阻塞，引发一系列问题。

- redis 3.0 及以下版本
	- 如果是集合类型，则遍历BigKey的元素，先逐个删除子元素，最后删除BigKey

![image-20220521140621204](D:\资料\该准备面试啦\redis\assets\image-20220521140621204.png)

- Redis 4.0以后
	- Redis在4.0后提供了异步删除的命令：unlink



### 8、Redis 过期删除策略

##### **如何设置过期时间？**

先说一下对 key 设置过期时间的命令。 设置 key 过期时间的命令一共有 4 个：

- `expire <key> <n>`：设置 key 在 n 秒后过期，比如 expire key 100 表示设置 key 在 100 秒后过期；
- `pexpire <key> <n>`：设置 key 在 n 毫秒后过期，比如 pexpire key2 100000 表示设置 key2 在 100000 毫秒（100 秒）后过期。
- `expireat <key> <n>`：设置 key 在某个时间戳（精确到秒）之后过期，比如 expireat key3 1655654400 表示 key3 在时间戳 1655654400 后过期（精确到秒）；
- `pexpireat <key> <n>`：设置 key 在某个时间戳（精确到毫秒）之后过期，比如 pexpireat key4 1655654400000 表示 key4 在时间戳 1655654400000 后过期（精确到毫秒）

当然，在设置字符串时，也可以同时对 key 设置过期时间，共有 3 种命令：

- `set <key> <value> ex <n>` ：设置键值对的时候，同时指定过期时间（精确到秒）；
- `set <key> <value> px <n>` ：设置键值对的时候，同时指定过期时间（精确到毫秒）；
- `setex <key> <n> <valule>` ：设置键值对的时候，同时指定过期时间（精确到秒）。

#####  如何判定 key 已过期了？

![img](D:\资料\java总资料\redis\assets\过期判断流程.jpg)



#####  过期删除策略有哪些？

Redis 中常见的过期删除策略有以下几种：

1. 定时删除：设置一个定时器来检查过期键并删除。这种方法会占用大量的 CPU 资源，不适合高并发场景。

2. 懒惰删除：当访问一个键时，先检查该键是否过期，如果过期则删除。这种方法不会占用大量的 CPU 资源，但可能会导致内存占用过高，因为过期键可能不会立即被删除。

3. 定期删除：每隔一段时间，遍历一定数量的键并删除过期键。这种方法可以控制内存占用，但可能会导致删除不及时。

4. 延迟删除：当对一个过期键进行读写操作时，检查该键是否过期，如果过期则不立即删除，而是将该键添加到一个链表中，定期删除链表中的过期键。这种方法可以避免定时删除占用大量的 CPU 资源和定期删除删除不及时的问题，但会增加内存占用和复杂度。

在 Redis 中，默认使用的是懒惰删除策略。可以通过修改配置文件中的`maxmemory-policy`参数来选择其他的过期删除策略。

好的，下面是比较常见的四种过期策略以及它们的优缺点：

| 过期策略               | 优点                                                | 缺点                                          |
| :--------------------- | :-------------------------------------------------- | :-------------------------------------------- |
| 定时删除               | 实现简单，可以立即释放内存                          | 时间复杂度高，可能会浪费一些内存              |
| 惰性删除               | 内存利用率高，只有在需要访问 key 时才会检查是否过期 | 可能会造成内存浪费，因为过期 key 不会立即释放 |
| 定期删除               | 时间复杂度相对较低，能够平滑释放内存                | 可能会出现大量过期 key 没有被删除的情况       |
| 基于内存使用的过期策略 | 内存利用率高，能够有效释放不必要的内存              | 实现复杂，需要考虑多个因素的影响              |

需要注意的是，不同的过期策略适用于不同的场景，我们需要根据实际情况来选择合适的过期策略。



### 9、Redis的内存淘汰策略

Redis提供6种内存淘汰策略，它们分别是：

1. noeviction：不淘汰，当内存不足时，新写入操作会报错。

2. allkeys-lru：在所有key中，选择最近最少使用的key淘汰。

3. volatile-lru：在设置了过期时间的key中，选择最近最少使用的key淘汰。

4. allkeys-random：在所有key中，随机选择一个key淘汰。

5. volatile-random：在设置了过期时间的key中，随机选择一个key淘汰。

6. volatile-ttl：在设置了过期时间的key中，选择剩余时间最短的key淘汰。

优缺点如下：

1. noeviction：不淘汰，会导致Redis内存耗尽，无法写入新的数据，因此一般不建议使用。

2. allkeys-lru：优点是淘汰的是最近最少使用的key，可以利用热点数据的局部性原理保留热点数据，缺点是如果存在很多长时间不用的key，可能会导致内存浪费，不适合使用。

3. volatile-lru：优点是只淘汰设置了过期时间的key，可以避免内存浪费，缺点是如果所有key都设置了过期时间，可能会导致热点数据被淘汰。

4. allkeys-random：淘汰随机key，简单高效，但可能会淘汰掉重要的数据。

5. volatile-random：淘汰设置了过期时间的随机key，相比于allkeys-random，可以避免淘汰重要的数据。

6. volatile-ttl：选择剩余时间最短的key淘汰，可以保留热点数据，但是可能会淘汰掉一些重要的数据。

在实际应用中，需要根据具体业务场景选择合适的内存淘汰策略。比如，如果缓存的数据有明确的过期时间，可以使用volatile-ttl策略；如果缓存的数据没有明确的过期时间，可以使用allkeys-lru策略。

### 10、Redis是如何实现LRU和LFU的

Redis中实现LRU（Least Recently Used）和LFU（Least Frequently Used）的方法是通过将缓存中的数据按照使用的频率和时间顺序排序，然后根据排序结果来确定哪些数据应该被删除。

对于LRU，Redis使用一个双向链表来维护数据的访问顺序，最近访问的数据放在链表的头部，最久未访问的数据放在链表的尾部。当插入新数据或者访问已有数据时，Redis会将该数据移动到链表的头部。当缓存空间不足时，Redis会从链表的尾部开始删除数据，即删除最久未访问的数据。

对于LFU，Redis使用一个有序集合来维护数据的访问频率，数据的访问次数作为有序集合的分值，每次访问时将该数据的分值加1，当缓存空间不足时，Redis会从有序集合中删除分值最小的数据，即访问次数最少的数据。

需要注意的是，Redis中实现LRU和LFU的方法都是基于近似算法的，即并不是完全精确的，但在实际使用中已经证明了其高效性和可靠性。



### 11、什么是缓存雪崩、击穿、穿透？

**缓存雪崩**是指缓存中大量的缓存数据在同一时间过期失效，导致请求直接打到数据库或应用服务器上，使得系统瞬间压力骤增，甚至引起系统崩溃的一种现象。

解决缓存雪崩问题的方法有以下几种：

1. 设置不同的缓存过期时间，避免大量缓存同时失效；
2. 使用分布式缓存，将缓存数据分散到多个节点上，避免单点故障；
3. 在缓存失效时，采用加锁或队列等机制，避免大量请求同时访问数据库或应用服务器；
4. 对于重要的数据，可以采用预热机制，提前将数据加载到缓存中，避免在请求到来时才进行缓存加载；
5. 在缓存层和应用层之间增加一层反向代理，当缓存失效时，反向代理可以直接返回默认值，避免请求直接打到应用服务器上。



**缓存击穿**是指在高并发的场景下，一个缓存的 key 在失效的瞬间，有大量的并发请求同时访问这个 key 对应的数据，导致请求全部落到数据库上，从而导致数据库瞬间压力过大甚至宕机的情况。这种情况下，缓存失去了它的意义。

为了解决缓存击穿问题，可以采取以下措施：

1. 设置热点数据永不过期：将一些热点数据设置成永不过期，保证这些数据始终存在于缓存中，避免缓存失效后导致大量请求落到数据库上。

2. 加锁：在缓存失效的时候，加锁防止并发访问数据库，只允许一个线程去查询数据库，其他线程等待查询结果。

3. 使用互斥锁：在缓存失效的时候，使用互斥锁来保证只有一个线程去查询数据库，其他线程等待查询结果。这种方式相比加锁，可以减少锁的粒度，提高并发度。

4. 缓存预热：系统启动时，将一些热点数据加载到缓存中，避免在高并发时缓存失效导致的问题。

5. 限流：通过限制并发请求的数量，避免缓存击穿问题的发生。



缓存穿透指的是一个请求查询一个不存在的数据，由于缓存中没有这个数据，所以会直接访问数据库，这样就会对数据库造成很大的压力，甚至引起宕机。攻击者可以通过故意查询不存在的数据来攻击系统，这就是缓存穿透攻击。

为了解决缓存穿透问题，可以采取以下措施：

1. 布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。

2. 缓存空对象：当一个查询返回的数据为空（不管是数据不存在还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

3. 限制并发请求：对同一时间段同一查询的并发请求，限制只能有一个请求能够到达数据库层面。可以使用互斥锁或者分布式锁来实现。

4. 数据预热：将系统中的数据预先加载到缓存中，这样就可以避免在用户请求时才去查询数据库造成的性能问题。

![图片](D:\资料\java总资料\redis\assets\061e2c04e0ebca3425dd75dd035b6b7b.png)



### 12、如何保证缓存和数据库的一致性问题









### 13、redis为什么这么快？

Redis 之所以这么快，主要有以下几个原因：

1. 数据存储方式：Redis 使用内存存储数据，相比传统的磁盘存储方式，内存存储的数据读写速度更快。

2. 单线程模型：Redis 使用单线程模型，避免了线程切换带来的开销，减小了锁的争用情况，从而提高了效率。

3. 异步非阻塞 I/O：Redis 使用异步非阻塞 I/O 模型，当执行 I/O 操作时，可以立即返回，不会阻塞线程，从而提高了并发处理能力。

4. 数据结构：Redis 提供了多种数据结构，如字符串、哈希、列表、集合、有序集合等，可以更加高效地处理不同类型的数据操作。

5. 持久化方式：Redis 提供了两种持久化方式，分别是 RDB 和 AOF，可以根据业务需求选择不同的持久化方式，保证数据的可靠性。

综上所述，Redis 之所以这么快，是因为它在多方面进行了优化，从而提高了数据处理的效率和性能。



### 14、redis单线程是在哪里

Redis的单线程体现在网络I/O和命令执行两个方面。

在网络I/O方面，Redis使用一个事件驱动的I/O模型，所有网络I/O操作都是在一个单独的线程中完成的，这个线程负责监听客户端连接请求，处理客户端发送的命令请求和发送响应结果。

在命令执行方面，Redis的所有命令都是在一个单独的线程中完成的，这个线程负责处理所有客户端发送的命令请求，执行命令并返回响应结果。这意味着Redis在任何时刻只有一个命令在执行，避免了多线程操作时的复杂性和线程安全问题。

因此，Redis的单线程架构使其在高并发情况下能够快速响应客户端请求，并且保证数据的一致性和可靠性。



### 15、为什么需要哨兵机制（有什么作用）

Redis的哨兵机制主要有以下作用：

1. 实现数据的备份和恢复：在Redis的主从复制模式中，主节点故障或宕机时，从节点需要接管故障节点的工作，包括数据的同步。但是，在某些情况下，例如主节点的网络连接断开或者磁盘空间不足等原因，从节点无法及时接管故障节点的工作。这时，就需要使用哨兵机制来实现数据的备份和恢复。
2. 检测主节点故障：在Redis的主从复制模式中，主节点需要不断地监测从节点的状态，以确保所有的数据都能够得到同步。因此，在某些情况下，主节点可能会出现故障，而此时如果没有哨兵机制，从节点将无法检测到主节点的故障，可能会导致数据同步出现问题。
3. 提高系统的可用性：当Redis的主从复制模式中的主节点故障时，可能会导致整个系统的崩溃。但是，如果使用哨兵机制，即使主节点出现故障，从节点也能够及时检测到，并自动进行故障转移，确保系统的可用性。
4. 支持故障排除：在Redis的主从复制模式中，如果出现故障，需要排除故障才能恢复系统的正常运行。使用哨兵机制可以帮助调试和排除故障，加快系统的故障排除速度。

因此，Redis的哨兵机制在保证数据的同步、检测主节点故障、提高系统的可用性和支持故障排除等方面起着重要作用。



### 16、哨兵工作原理

Redis哨兵机制的工作原理：

1. 故障检测与转移：当Redis的主节点（master）出现故障或宕机时，Redis的从节点（slave）需要自动将数据同步到备用主节点（standby master）上。为了实现这一过程，Redis提供了故障检测与转移的功能。

当Redis的主节点故障时，AFO（自动故障转移）检测到这种情况后，会自动将从节点设置为新的主节点，并将数据同步到备用主节点上。此时，从节点会开始监测新的主节点的状态，确保数据的一致性。当新的主节点稳定后，从节点会将数据同步回原来的主节点。

当Redis的从节点故障时，AFO 检测到这种情况后，会自动将从节点设置为新的主节点，并将数据同步到备用主节点上。此时，从节点会开始监测新的主节点的状态，确保数据的一致性。当新的主节点稳定后，从节点会将数据同步回原来的主节点。

1. 数据备份和恢复：当Redis的主从节点之间出现数据同步问题时，可以使用哨兵机制来实现数据的备份和恢复。具体来说，可以将故障节点的数据备份到另一个节点上，当原来的主节点故障或宕机时，可以使用备份数据来恢复故障节点的数据。
2. 提高系统可用性：当Redis的主从节点之间出现数据同步问题时，可能会导致整个系统的崩溃。但是，如果使用哨兵机制，即使主节点出现故障，从节点也能够及时检测到，并自动进行故障转移，确保系统的可用性。
3. 支持故障排除：在Redis的主从复制模式中，如果出现故障，需要排除故障才能恢复系统的正常运行。使用哨兵机制可以帮助调试和排除故障，加快系统的故障排除速度。



哨兵节点主要负责三件事情：**监控、选主、通知**。

1. 监控：哨兵节点需要实时监控其所在的Redis集群的状态，包括主节点和从节点的状态、数据的变化等。通过监控，哨兵节点可以及时发现集群中的故障节点或从节点，并通过自动故障转移机制将故障节点的工作接管过来。
2. 选主：当Redis集群中出现故障节点时，哨兵节点需要代替故障节点成为新的主节点。为了确保故障转移的正确性，哨兵节点需要选择一个可靠的从节点作为新的主节点，并将其作为自己的副本。在选择从节点时，哨兵节点需要考虑很多因素，例如从节点的数据一致性、快速故障切换等。
3. 通知：哨兵节点需要及时将集群中的变化通知给所有的从节点。当主节点或从节点发生变化时，哨兵节点需要通知所有的从节点，并将新的主节点或从节点的信息同步到所有的从节点。通知可以及时纠正数据偏差、减少数据延迟等问题，保证整个Redis集群的正常运行。



哨兵节点主要通过以下几种方式来监控节点：

1. 监控主节点和从节点的状态：哨兵节点需要实时监控其所在的Redis集群中的主节点和从节点的状态，包括是否正常运行、是否有故障等。一旦发现有问题的节点，哨兵节点会立即进行故障检测和转移操作。
2. 监控数据变化：哨兵节点还需要监控Redis集群中数据的变化情况，及时发现数据不一致的情况并进行处理。例如，当主节点或从节点发生变化时，哨兵节点需要及时通知所有的从节点，并将新的主节点或从节点的信息同步到所有的从节点。
3. 监控故障节点：哨兵节点需要实时监控Redis集群中的故障节点，并通过自动故障转移机制将故障节点的工作接管过来。当检测到有故障节点时，哨兵节点会立即通知相应的从节点，并将其作为新的主节点进行操作。
4. 选择代理节点：哨兵节点还需要选择一个可靠的从节点作为代理节点，并将其作为自己的副本。在选择代理节点时，哨兵节点需要考虑很多因素，例如从节点的数据一致性、快速故障切换等。

在判断主节点是否真的故障了方面，哨兵节点主要基于以下几个因素：

1. 监控数据变化：哨兵节点需要实时监控Redis集群中数据的变化情况，及时发现数据不一致的情况并进行处理。如果发现有数据不一致的情况，哨兵节点会立即通知相应的从节点进行处理。
2. 故障信号：哨兵节点可以监测到主节点发出的故障信号，例如SIGTERM、SIGINT等。如果检测到主节点已经故障，哨兵节点会立即通知相应的从节点，并将其作为新的主节点进行操作。
3. 系统状态：哨兵节点可以监测到Redis集群的系统状态，例如报警信息、系统调用状态等。如果检测到Redis集群处于不稳定状态，哨兵节点会立即通知相应的从节点，并将其作为新的主节点进行操作。
4. 心跳检测：哨兵节点还可以检测到主节点的心跳信号，例如PING操作。如果检测到主节点的心跳异常，哨兵节点会立即通知相应的从节点，并将其作为新的主节点进行操作。

综上所述，哨兵节点通过监控主节点和从节点的状态、数据变化、故障信号、系统状态以及心跳检测等多种方式来判断主节点是否真的故障了。



### 17、如何判断主节点真的故障了？



哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。



### 18、主观下线？难道还有客观下线？

客观下线只适用于主节点。





### 19、哨兵模式下，哪个哨兵进行主从故障转移？

那谁来作为候选者呢？

候选者如何选举成为 Leader？



为什么哨兵节点至少要有 3 个？



### 20、主从故障转移的过程是怎样的？

主从故障转移操作包含以下四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。
- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
- 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；



竞选考察？





### 21、redis如何实现延迟队列？



### 22、redis的管道有什么用？

Redis管道是一种用于优化Redis性能的方式，它可以在客户端和Redis服务器之间建立一个管道，其中可以将多个Redis命令打包在一起，然后一次性发送给Redis服务器执行。这种方式可以减少客户端与Redis服务器之间的通信次数，从而提高Redis的性能。

使用Redis管道的好处主要有以下几点：

1. 减少网络开销：由于Redis管道能够将多个Redis命令打包在一起发送给Redis服务器，因此可以减少网络通信的次数和开销。

2. 提高吞吐量：由于Redis管道可以并发地执行多个Redis命令，因此可以提高Redis的吞吐量，从而更快地处理请求。

3. 降低延迟：由于Redis管道可以一次性发送多个Redis命令，因此可以减少客户端和Redis服务器之间的通信次数，从而降低请求的延迟。

总之，Redis管道是一种非常有用的工具，可以帮助我们提高Redis的性能和吞吐量，降低延迟，从而更好地满足业务需求。

### 23、redis的事务支持回滚吗？



### 24、redis如何实现分布式锁？

Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：

- 如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
- 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。

基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。

- 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 **SET 命令带上 NX 选项来实现加锁**；
- 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 **EX/PX** 选项，**设置其过期时间**；
- 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，**我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值**，用于标识客户端；

满足这三个条件的分布式命令如下：

```c
SET lock_key unique_value NX PX 10000 
```

- lock_key 就是 key 键；
- unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；
- NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
- PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。

而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。

可以看到，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。

```c
// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。



### 25、红锁RedLock

为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。

它是基于**多个 Redis 节点**的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。官方推荐是至少部署 5 个 Redis 节点，而且都是主节点，它们之间没有任何关系，都是一个个孤立的节点。

Redlock 算法的基本思路，**是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败**。

这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。

Redlock 算法加锁三个过程：

- 第一步是，客户端获取当前时间（t1）。
- 第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作：
	- 加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。
	- 如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。
- 第三步是，一旦客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。

可以看到，加锁成功要同时满足两个条件（*简述：如果有超过半数的 Redis 节点成功的获取到了锁，并且总耗时没有超过锁的有效时间，那么就是加锁成功*）：

- 条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁；
- 条件二：客户端从大多数节点获取锁的总耗时（t2-t1）小于锁设置的过期时间。

加锁成功后，客户端需要重新计算这把锁的有效时间，计算的结果是「锁最初设置的过期时间」减去「客户端从大多数节点获取锁的总耗时（t2-t1）」。如果计算的结果已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。

加锁失败后，客户端向**所有 Redis 节点发起释放锁的操作**，释放锁的操作和在单节点上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了



Redlock 算法是一种基于时间戳的分布式锁算法，其实现原理如下：

1. 客户端申请锁。客户端向所有的 Redis 实例发出锁的申请，只有超过半数的 Redis 实例报告获取锁成功，才能算真正获取到锁。
2. 对象检查。Redis 实例会检查当前是否有其他客户端持有锁。如果有，则该客户端将被阻塞，直到锁被释放。
3. 红锁判断。如果锁已经被其他客户端持有，则该客户端将被阻塞，直到锁被释放。如果没有其他客户端持有锁，则该客户端将成功获取到锁，并退出循环。

在 Redis 集群中，Redlock 算法的锁的粒度是 Redis 实例，而不是数据库。因此，在 Redis 集群中，多个 Redis 实例可以共享同一个锁，从而实现分布式锁的功能。同时，Redis 集群中的每个实例都可以持有多个 RLock 对象，用于实现红锁。

为了提高分布式锁的可用性和可靠性，可以使用适当的超时时间、使用多个 Redis 实例、使用乐观锁等技术。

Redlock 算法的优缺点如下：

1. 优点：

- Redlock 算法支持多个客户端同时获取锁，提高了并发性能。
- Redlock 算法使用时间戳作为锁的标识，相比于数据库的行为更加符合计算机内存的处理方式。
- Redlock 算法的高可用性得益于 Redis 集群的特性，多个 Redis 实例可以共享同一个锁。

1. 缺点：

- Redlock 算法的实现较为复杂，相比于其他分布式锁算法，学习曲线较陡峭。
- Redlock 算法需要在每个节点上保存一定数量的计数器，如果节点崩溃，可能导致数据不一致。
- Redlock 算法的缺省超时时间过短，可能导致资源泄漏和死锁的风险。

总的来说，Redlock 算法是一种高并发、高可用性的分布式锁算法，但其实现相对复杂，需要更多的资源和注意事项。在使用时需要注意事项和细节，以保证应用程序的正常运行。



##### redlock加锁成功的条件

Redlock算法要求至少半数以上的Redis节点都能够成功获取锁才算加锁成功。具体来说，假设有N个Redis节点，要获取一把名为lock的锁，Redlock算法的加锁过程如下：

1. 获取当前时间戳now。
2. 依次向N个Redis节点发起加锁请求，每个请求包括锁名称lock、随机字符串value、过期时间expire和当前时间戳now。
3. 统计有多少个Redis节点成功获取了锁，若成功获取锁的节点数量大于N/2，则认为加锁成功。
4. 如果加锁成功，则返回锁的value和expire信息，否则尝试向已经获取锁的节点释放锁。

需要注意的是，Redlock算法并不是绝对可靠的，如果有大量的Redis节点同时出现网络故障或者CPU负载过高等问题，可能会导致加锁失败。因此，建议在使用Redlock算法时，结合其他机制，例如设置锁的过期时间、重试机制等，来提高系统的稳定性。



1. 什么是分布式锁？

答：分布式锁是一种用于控制多个进程或多台服务器之间访问共享资源的机制。在分布式系统中，由于多个进程或多台服务器之间的通信可能存在延迟或不可靠性，因此需要使用分布式锁来保证数据的一致性和正确性。

1. Redlock的基本原理是什么？

答：Redlock的基本原理是使用多个独立的Redis实例来实现分布式锁。当一个进程需要获取锁时，它会向多个Redis实例分别发送Acquire请求，每个请求包含一个随机的锁标识符和一个唯一的客户端ID。如果某个Redis实例成功地获取了锁，则它会返回一个Acquire响应，包含锁的标识符和一个唯一的token。进程可以使用这个token来释放锁。当进程释放锁时，它会向所有Redis实例发送一个Release请求，以释放所有已经获取的锁。

1. Redlock的优点和缺点是什么？

答：Redlock的优点是它可以在多个Redis实例之间协调，从而实现强大的分布式锁。此外，Redlock具有较高的可靠性和可扩展性。然而，Redlock的缺点是它的实现比较复杂，需要考虑多种情况，如网络故障、时钟漂移等。此外，Redlock可能会出现误判，即某些进程可能会同时获取到同一个锁。

1. 如何使用Redlock实现分布式锁？

答：使用Redlock实现分布式锁需要以下步骤：

1）连接多个Redis实例，并创建Jedis对象。

2）在获取锁时，向多个Redis实例发送Acquire请求，并设置超时时间。如果其中一个Redis实例成功获取锁，则返回Acquire响应，将锁的标识符和token保存到本地。

3）在释放锁时，向所有Redis实例发送Release请求，以释放所有已经获取的锁。



### 26、redis的命令模式

Redis的命令模式有以下几种：

1. 单机模式：Redis运行在单机上，所有的读写操作都在同一个进程中进行。

2. 主从模式：Redis通过主从复制实现数据的读写分离，主节点处理写操作，从节点处理读操作。

3. 哨兵模式：Redis通过哨兵进程监控主节点的状态，并自动将从节点转变为主节点，保证系统的高可用性。

4. 集群模式：Redis通过集群模式实现数据分片，将数据分散存储在多个节点中，提高系统的扩展性和容错性。

以上四种命令模式可以满足不同场景下的需求，开发者可以根据实际情况选择适合自己的模式。



### 27、分布式缓存技术

分布式缓存是大数据应用中常用的技术，常见的技术选型方案有以下几种：

1. Redis：Redis提供了数据结构丰富、简单易用、支持分布式等特点，因此在分布式缓存中被广泛使用。但是，Redis的单线程模型限制了其性能，当缓存操作的逻辑复杂时，会影响性能。
2. Memcached：Memcached是一个高性能的内存缓存系统，支持对键值对的存储和快速的读写操作，因此在分布式缓存中也被广泛使用。但是，Memcached只支持对键值对的存储，不支持对其他数据结构的支持。
3. Tair：Tair是一个开源的分布式内存对象缓存系统，支持多种数据结构的存储，包括列表、哈希表、集合等，同时提供了高效的读写性能。Tair的优点是性能高、易于扩展、可靠性好，适合大规模的分布式缓存应用。
4. RocketMQ：RocketMQ是阿里巴巴推出的一款分布式消息队列系统，支持多种消息中间件，包括Redis、Memcached等，因此也可以用作分布式缓存系统。RocketMQ的优点是性能好、稳定性高、可扩展性强，适合大规模的分布式缓存应用。
5. Kafka：Kafka是一个分布式流处理系统，支持多种消息中间件，包括Redis、Memcached等，因此也可以用作分布式缓存系统。Kafka的优点是性能好、可扩展性强、可靠性高，适合大规模的分布式缓存应用。

表格比较：

| 方案名称  |                     描述                     |           性能评估           |      适用场景      |
| :-------: | :------------------------------------------: | :--------------------------: | :----------------: |
|   Redis   |    支持数据结构丰富、简单易用、支持分布式    |     单线程模型限制了性能     | 适合小规模缓存场景 |
| Memcached | 高性能内存缓存、支持对键值对的存储和快速读写 |     只支持对键值对的存储     | 适合小规模缓存场景 |
|   Tair    |   多种数据结构支持、高效读写性能、可靠性好   |  性能高、易于扩展、可靠性好  | 适合大规模缓存场景 |
| RocketMQ  |      支持多种消息中间件、适合分布式缓存      | 性能好、稳定性高、可扩展性强 | 适合大规模缓存场景 |
|   Kafka   |      支持多种消息中间件、适合分布式缓存      | 性能好、可扩展性强、可靠性高 | 适合大规模缓存场景 |

### 28、redis的发布订阅模式

Redis的发布订阅模式是一种消息通信模式，它包含两个主要的参与者：发布者和订阅者。发布者将消息发送到一个特定的频道，订阅者可以选择订阅一个或多个频道，并接收发布者发送到这些频道的消息。

Redis的发布订阅模式可以通过以下代码实现：

1. 发布者使用PUBLISH命令将消息发送到指定的频道，例如：

```c
PUBLISH channel message
```

2. 订阅者使用SUBSCRIBE命令订阅一个或多个频道，例如：

```
SUBSCRIBE channel
```

3. 订阅者可以使用UNSUBSCRIBE命令取消订阅一个或多个频道，例如：

```
UNSUBSCRIBE channel
```

##### Redis的发布订阅模式的优点包括：

1. 简单易用：Redis的发布订阅模式非常易于使用，只需要几个简单的命令即可实现消息的发布和订阅。

2. 高效可靠：Redis的发布订阅模式使用了高效的消息传递机制，保证了消息的可靠传递。

3. 扩展性好：Redis的发布订阅模式支持多个订阅者同时订阅同一个频道，可以满足多个客户端同时订阅同一个消息的需求。

**Redis的发布订阅模式的缺点包括：**

1. 不支持消息确认机制：Redis的发布订阅模式不支持消息确认机制，即发布者无法得知消息是否被订阅者正确接收。

2. 不支持消息持久化：Redis的发布订阅模式不支持消息持久化，即消息无法在断电等异常情况下得到保存。

3. 不支持多主节点：Redis的发布订阅模式不支持多主节点，即在集群环境下无法保证消息的全局唯一。

总之，Redis的发布订阅模式是一种简单易用、高效可靠、扩展性好的消息通信模式，适用于多个客户端之间的协作、实时消息推送等场景。



### 29、Memcached和Redis的比较：

|     特性     |                          Memcached                           |                            Redis                             |
| :----------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 数据存储方式 |                          键值对存储                          |                key-value存储、哈希表、集合等                 |
| 支持数据类型 |                     简单的key-value类型                      |                  list、set、hash等数据结构                   |
|  内存使用率  |                 高，默认情况下利用率超过90%                  |                较高，可以通过设置参数进行调整                |
|  持久化方式  |            支持数据持久化，可以将数据保存到磁盘上            |         不支持数据持久化，数据一旦写入内存就无法更改         |
|  数据安全性  |     支持多种安全机制，包括数据加密、数据备份和数据恢复等     |        不支持数据安全机制，数据一旦写入内存就无法更改        |
|   处理速度   |    Redis采用异步I/O技术，性能较高，可以处理大量的读写请求    | Memcached采用非阻塞I/O技术，性能较低，只能处理小量的读写请求 |
|   适用场景   | Memcached适用于小规模的缓存场景，如缓存热点数据、缓存热门话题等 | Redis适用于大规模的缓存场景，如缓存所有用户的订单信息、缓存热门商品信息等 |

综上所述，Memcached和Redis都是常用的分布式缓存系统，具有不同的特点和适用场景。在选择使用哪种缓存系统时，需要根据具体的应用场景和需求来进行选择。



### 说一下 Redis 和 Memcached 的区别和共同点

现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！不过，了解 Redis 和 Memcached 的区别和共同点，有助于我们在做相应的技术选型的时候，能够做到有理有据！

**共同点**：

1. 都是基于内存的数据库，一般都用来当做缓存使用。
2. 都有过期策略。
3. 两者的性能都非常高。

**区别**：

1. **Redis 支持更丰富的数据类型（支持更复杂的应用场景）**。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
2. **Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中。**
3. **Redis 有灾难恢复机制。** 因为可以把缓存中的数据持久化到磁盘上。
4. **Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。**
5. **Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。**
6. **Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。** （Redis 6.0 针对网络数据的读写引入了多线程）
7. **Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。**
8. **Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。**



### 30、redis是单线程的，怎么监听多个时间？

虽然 Redis 是单线程的，但它采用了**事件驱动模型来实现高效的网络通信**，因此可以高效地处理大量的并发请求。具体来说，**Redis 的网络事件处理器采用了 Reactor 模**式，**即通过一个主线程来监听所有的客户端连接，一旦有客户端连接到来，就会将该连接的信息封装成一个事件并加入到事件队列中，然后主线程会不断地从事件队列中取出事件，并根据事件类型来执行相应的操作，如接收客户端的请求、执行命令等。**

在这种事件驱动的模型下，**每个客户端连接会被封装成一个文件描述符，而 Redis 使用了类似于 epoll 的机制来监听这些文件描述符上的事件，从而实现高效的网络通信。此外，Redis 还使用了多个 I/O 线程来处理网络 I/O，这些线程和主线程之间通过消息队列进行通信，进一步提高了 Redis 的并发处理能力。**

因此，虽然 Redis 是单线程的，但它通过事件驱动模型和多线程的方式来处理大量的客户端连接，从而实现了高效的并发处理。

文件事件处理器（file event handler）主要是包含 4 个部分：

- 多个 socket（客户端连接）
- IO 多路复用程序（支持多个客户端连接的关键）
- 文件事件分派器（将 socket 关联到相应的事件处理器）
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）



### 31、Redis的后台线程？

是的，我了解Redis的后台线程。Redis有4个后台线程，分别是：

1. RDB持久化线程：将内存中的数据异步写入磁盘，实现数据持久化。

2. AOF持久化线程：将写命令追加到AOF文件中，实现数据持久化。

3. 清除过期键线程：定期清除已经过期的键，释放内存空间。

4. 主从复制线程：将主节点的数据同步到从节点中，实现数据备份和负载均衡。

这些后台线程都是在Redis的主线程之外运行的，通过异步方式实现数据持久化、内存管理和数据同步等功能，保证Redis的高性能和高可用性。



### 32、Redis如何实现事务，Redis事务不满足原子性？



Redis 可以通过 **`MULTI`，`EXEC`，`DISCARD` 和 `WATCH`** 等命令来实现事务(Transaction)功能。

```
> MULTI
OK
> SET PROJECT "JavaGuide"
QUEUED
> GET PROJECT
QUEUED
> EXEC
1) OK
2) "JavaGuide"
```



[`MULTI`](https://redis.io/commands/multi) 命令后可以输入多个命令，Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 [`EXEC`](https://redis.io/commands/exec) 命令后，再执行所有的命令。

这个过程是这样的：

1. 开始事务（`MULTI`）；
2. 命令入队(批量操作 Redis 的命令，先进先出（FIFO）的顺序执行)；
3. 执行事务(`EXEC`)。

你也可以通过 [`DISCARD`](https://redis.io/commands/discard) 命令取消一个事务，它会清空事务队列中保存的所有命令。

```
> MULTI
OK
> SET PROJECT "JavaGuide"
QUEUED
> GET PROJECT
QUEUED
> DISCARD
OK
```



你可以通过[`WATCH`](https://redis.io/commands/watch) 命令监听指定的 Key，当调用 `EXEC` 命令执行事务时，如果一个被 `WATCH` 命令监视的 Key 被 **其他客户端/Session** 修改的话，整个事务都不会被执行。

```
# 客户端 1
> SET PROJECT "RustGuide"
OK
> WATCH PROJECT
OK
> MULTI
OK
> SET PROJECT "JavaGuide"
QUEUED

# 客户端 2
# 在客户端 1 执行 EXEC 命令提交事务之前修改 PROJECT 的值
> SET PROJECT "GoGuide"

# 客户端 1
# 修改失败，因为 PROJECT 的值被客户端2修改了
> EXEC
(nil)
> GET PROJECT
"GoGuide"
```



不过，如果 **WATCH** 与 **事务** 在同一个 Session 里，并且被 **WATCH** 监视的 Key 被修改的操作发生在事务内部，这个事务是可以被执行成功的（相关 issue：[WATCH 命令碰到 MULTI 命令时的不同效果](https://github.com/Snailclimb/JavaGuide/issues/1714)）。

事务内部修改 WATCH 监视的 Key：

```
> SET PROJECT "JavaGuide"
OK
> WATCH PROJECT
OK
> MULTI
OK
> SET PROJECT "JavaGuide1"
QUEUED
> SET PROJECT "JavaGuide2"
QUEUED
> SET PROJECT "JavaGuide3"
QUEUED
> EXEC
1) OK
2) OK
3) OK
127.0.0.1:6379> GET PROJECT
"JavaGuide3"
```



事务外部修改 WATCH 监视的 Key：

```
> SET PROJECT "JavaGuide"
OK
> WATCH PROJECT
OK
> SET PROJECT "JavaGuide2"
OK
> MULTI
OK
> GET USER
QUEUED
> EXEC
(nil)
```

### 33、Redis 性能优化（重要）







### 34、Redis 集群

1. ##### 什么是 Sentinel？ 有什么用？

	```
	Redis Sentinel是Redis的高可用性解决方案，它可以监控Redis实例的健康状况，并在主节点故障时自动将从节点切换为新的主节点，从而保证Redis服务的可用性。
	
	具体来说，Sentinel可以自动监测Redis实例的状态，包括主节点和从节点的状态，并在主节点不可用时自动进行故障转移，将其中的一个从节点升级为新的主节点，然后将其他从节点切换到新的主节点上，从而实现高可用性的Redis服务。此外，Sentinel还可以进行自动故障恢复，当Redis实例恢复时，Sentinel可以自动将其重新纳入集群中。
	
	Sentinel的使用可以提高Redis服务的可用性和可靠性，能够避免因为主节点故障导致服务不可用的情况，从而保障服务的稳定性和连续性。
	```

	

2. ##### Sentinel 如何检测节点是否下线？主观下线与客观下线的区别?

	```
	Redis Sentinel 会通过心跳检测来检测节点是否下线。Sentinel 会向被监控的 Redis 节点发送 PING 命令来检测连接是否正常，如果连续多次 PING 命令失败，Sentinel 就会认为该节点下线。
	
	主观下线和客观下线的区别在于判断节点是否下线的依据不同。主观下线是指 Sentinel 在自己的视角下，认为节点已经下线，但是其他 Sentinel 可能认为该节点仍然在线。这种情况通常发生在网络分区或者故障恢复期间，当 Sentinel 无法与主服务器或者从服务器通信时，就会认为该节点下线。
	
	客观下线是指多个 Sentinel 在同一时间内都认为节点已经下线，这种情况下，Sentinel 会向其他客户端广播该节点下线的消息，从而触发自动故障迁移，将原本由该节点负责的任务转移到其他节点上。
	```

	

3. ##### Sentinel 是如何实现故障转移的？

	```
	Redis Sentinel 是 Redis 官方提供的一种高可用性解决方案，能够监控 Redis 实例的状态，并在主节点故障时自动完成主从切换，确保系统的高可用性。Redis Sentinel 的故障转移过程如下：
	
	1. 当 Redis 主节点发生故障时，Sentinel 会检测到该节点不可用，然后通过投票机制选出一个新的主节点。
	2. Sentinel 会向新的主节点发送 SLAVEOF NO ONE 命令，将其设置为新的主节点。
	3. Sentinel 会将原来的主节点设置为新主节点的从节点，同时将原来的从节点升级为新的主节点的从节点。
	4. Sentinel 会将其他从节点设置为新的主节点的从节点。
	
	通过这个过程，Redis Sentinel 可以快速地完成主从切换，确保系统的高可用性。需要注意的是，在故障转移过程中，可能会出现数据丢失的情况，因为未同步的数据可能会在主从切换时丢失。为了避免数据丢失，建议使用 Redis Cluster 或者使用 Redis 主从复制的方式来保证数据的可靠性。
	```

	

4. ##### 为什么建议部署多个 sentinel 节点（哨兵集群）？

	```
	建议部署多个 Sentinel 节点的主要原因是为了提高 Redis 的高可用性和可靠性。当 Redis 主节点宕机时，哨兵集群可以自动地将一个从节点升级为主节点，从而保证 Redis 系统的可用性。如果只部署一个 Sentinel 节点，那么当这个节点宕机时，Redis 系统就会失去高可用性和可靠性。
	
	另外，多个 Sentinel 节点可以提高系统的容错能力。如果某个 Sentinel 节点宕机，其他 Sentinel 节点可以接替其工作，保证 Redis 系统的可用性。此外，多个 Sentinel 节点还可以提供更好的服务质量和更快的故障恢复时间。
	
	总之，建议部署多个 Sentinel 节点是为了提高 Redis 的高可用性、可靠性、容错能力和服务质量。
	```

	

	##### Sentinel 如何选择出新的 master（选举机制）?

	```
	Redis Sentinel 是 Redis 的高可用性解决方案，它可以监控 Redis 实例的运行状态，并在主节点不可用时自动进行故障转移。在 Sentinel 中，有一个主节点负责处理客户端请求，多个从节点作为主节点的备份。当主节点出现故障时，Sentinel 会从从节点中选举一个新的主节点。
	
	Sentinel 通过以下机制选择新的主节点：
	
	1. Sentinel 会将当前 Sentinel 群集中的所有 Sentinel 都看做候选人，并进行选举。
	
	2. 每个 Sentinel 会向其他 Sentinel 发送 "SENTINEL is-master-down-by-addr" 命令，请求确认主节点是否已经下线。
	
	3. 如果超过 Sentinel 群集的大多数节点都确认主节点已经下线，那么该主节点将被标记为下线状态，并进行故障转移。
	
	4. Sentinel 会从当前已知的从节点中选举一个新的主节点，并将其升级为主节点。如果当前已知的从节点中不存在可用的从节点，则需要等待新的从节点加入。
	
	5. 新的主节点被选定后，Sentinel 会向客户端广播新的主节点的地址，客户端可以重新连接新的主节点。
	
	总的来说，Sentinel 采用多数投票机制来进行选举，只有在超过 Sentinel 群集的大多数节点确认主节点已经下线时，才会进行故障转移。这种机制可以保证选举出来的主节点是可靠的，并且可以防止脑裂现象的发生。
	```

	如何从 Sentinel 集群中选择出 Leader ？

	```
	在Sentinel集群中，每个Sentinel都可以成为Leader，但只有一个Sentinel实例成为Leader，其他Sentinel实例处于从属状态。Sentinel集群中的Leader负责监控Redis主从节点的状态，并在主节点出现故障或下线时，自动将从节点升级为主节点。
	
	当Sentinel集群中存在多个Sentinel实例时，它们会使用Raft算法进行Leader选举。Raft算法是一种分布式一致性算法，其目的是确保在多个节点之间达成一致性，保证系统的可用性和可靠性。
	
	在Sentinel集群中，每个Sentinel实例都会向其他Sentinel实例发送心跳包以保持通信。如果一个Sentinel实例在一段时间内没有收到其他Sentinel实例的心跳包，则会认为其他Sentinel实例已经失效，并发起Leader选举。Sentinel实例之间的通信和Leader选举过程都是自动的，无需用户干预。
	
	当有新的Sentinel实例加入集群时，它会自动发现其他Sentinel实例，并参与到Leader选举中。在Sentinel集群中，Leader的状态会被所有Sentinel实例共享，以确保集群中所有节点都具有相同的视图。
	```

	Sentinel 可以防止脑裂吗？

	```
	Sentinel可以帮助防止脑裂（split-brain）的问题。在Redis集群中，脑裂是指由于网络分区或其他原因，导致不同的Redis节点之间失去联系，同时对同一个key进行写操作，导致数据不一致的问题。为了防止脑裂，Sentinel会监控Redis节点的健康状态，并在主节点失效时自动进行故障转移，将从节点晋升为新的主节点，从而保证Redis集群的高可用性和数据一致性。同时，Sentinel还提供了Quorum机制，可以确保只有在大多数Sentinel节点都认为主节点失效时，才会进行故障转移，避免了因网络分区等问题导致的误判。因此，使用Sentinel可以有效地防止脑裂问题。
	
	
	```

#### **Redis Cluster**：

##### 为什么需要Redis Cluster？

Redis Cluster是一个分布式的Redis数据库解决方案，它解决了单机Redis的容量限制、性能瓶颈和高可用性等问题。通常情况下，一个单机Redis实例的容量是有限的，它不能存储大量的数据，而且随着数据量的增加，其性能也会受到影响。Redis Cluster通过将数据分布到多个节点上来扩展Redis的容量和性能，并且通过复制机制和自动故障转移机制来提高Redis集群的可用性。

##### Redis Cluster的优势是什么？

Redis Cluster提供了以下优势：

1. 高可用性：Redis Cluster采用多主复制和自动故障转移机制来保证高可用性，即使有一些节点宕机了，Redis Cluster也能够自动发现并且重新选举新的主节点。

2. 分布式：Redis Cluster采用分片机制来实现数据的分布式存储，使得Redis的容量和性能都能够得到扩展。

3. 易于扩展：Redis Cluster支持在线扩展，可以动态添加或删除节点，而且不需要停机或者数据迁移。

4. 低延迟：Redis Cluster采用内存存储和单线程模型，使得其具有非常低的响应延迟和高并发性能。

##### Redis Cluster是如何分片的？

Redis Cluster采用哈希槽分片机制来实现数据的分布式存储。在Redis Cluster中，所有的键值对都被分配到一个固定数量的哈希槽中，这个数量是16384个。每个节点都保存了一部分哈希槽的数据。当一个客户端请求一个键值对时，Redis Cluster会根据这个键值对的哈希值来确定它所属的哈希槽，并且将请求转发到负责这个哈希槽的节点上。

##### 为什么Redis Cluster的哈希槽是16384个？

16384是一个2的14次方，这个数目是一个比较合适的分片数量，它既能够保证数据分布均匀，又不会导致节点之间的负载不均衡。此外，这个数目也比较容易被整除或者整除其他的数字，使得Redis Cluster的扩展和维护都变得更加容易。

##### 如何确定给定key的应该分布到哪个哈希槽中？

Redis Cluster采用CRC16算法来计算键值对的哈希值。具体来说，Redis Cluster会将键值对的key作为CRC16算法的输入，得到一个16位的哈希值，然后将这个哈希值对16384取模，得到一个0到16383之间的整数，这个整数就是这个键值对所属的哈希槽的编号。

##### Redis Cluster支持重新分配哈希槽吗？

是的，Redis Cluster支持重新分配哈希槽。当Redis Cluster中添加或删除节点时，哈希槽会重新分配到新的节点上。Redis Cluster会将需要迁移的哈希槽的数据从旧的节点上复制到新的节点上，直到所有的数据都被迁移完成。在哈希槽迁移过程中，Redis Cluster仍然可以提供服务，但是可能会影响性能。

##### Redis Cluster扩容缩容期间可以提供服务吗？

是的，Redis Cluster在扩容或缩容期间仍然可以提供服务。当添加或删除节点时，Redis Cluster会自动将哈希槽迁移到新的节点上，直到所有的数据都被迁移完成。在迁移过程中，Redis Cluster仍然可以提供服务，但是可能会影响性能。

##### Redis Cluster中的节点是怎么进行通信的？

Redis Cluster中的节点采用gossip协议进行通信。每个节点都会向其他节点发送消息，告诉它们自己的状态和哈希槽的分配情况。当一个节点发现其他节点的状态发生变化时，它会向其他节点发送消息，告诉它们自己的状态和哈希槽的分配情况。通过这种方式，所有的节点都能够了解整个集群的状态，并且进行自动故障转移和哈希槽迁移。

##### 当Redis Cluster中的一个节点宕机了，Redis会自动进行分片转移。

确保数据的可用性。具体分片转移的步骤如下：

1. 集群中的其他节点会检测到宕机节点的失联，并将该节点标记为下线状态。
2. 如果宕机节点是主节点，那么它的从节点中会选举一个新的主节点。
3. 如果宕机节点是从节点，那么它会尝试重新连接其他主节点，并请求成为其从节点。
4. 如果宕机节点上有槽位分配了数据，那么这些槽位会被重新分配到其他节点上。

在分片转移期间，Redis Cluster仍然可以正常处理读写请求，但会根据当前节点状态选择一个新的主节点或从节点进行处理。在分片转移完成后，Redis Cluster会自动恢复正常的工作状态。



##### 当向Redis Cluster添加新的节点时，它会自动将哈希槽分配给新节点。

Redis Cluster使用哈希槽（hash slot）来分片数据，每个哈希槽可以存储一个键值对。Redis Cluster默认有16384个哈希槽，当添加一个节点时，Redis Cluster会计算出新节点应该管理的哈希槽范围，并将一部分哈希槽转移给新节点。转移哈希槽的过程是渐进的，直到所有哈希槽都被重新分配。这个过程是自动进行的，无需手动干预。

需要注意的是，当添加一个新节点时，由于数据的重新分布可能会导致Redis Cluster在一段时间内处于不稳定状态，因此我们需要在添加节点时注意整个集群的可用性，确保数据的一致性和高可用性。





### 35、redis网络模型

好的，下面是常见的四种网络IO模型的比较表格：

| 网络IO模型 | 同步/异步 | 阻塞/非阻塞 | 多路复用 | 并发性能 | 适用场景 |
| :--------: | :-------: | :---------: | :------: | :------: | :------: |
|   阻塞IO   |   同步    |    阻塞     |    -     |    低    |  单连接  |
|  非阻塞IO  |   同步    |   非阻塞    |    -     |    中    |  多连接  |
|   IO复用   |   同步    | 阻塞/非阻塞 |   支持   |    高    |  多连接  |
|   异步IO   |   异步    |   非阻塞    |    -     |  非常高  |  多连接  |

注释：

- 同步：用户线程发起的IO操作需要等待IO操作完成才能继续执行后面的代码；
- 异步：用户线程发起的IO操作不需要等待IO操作完成，可以继续执行后面的代码；
- 阻塞：用户线程发起的IO操作会一直等待，直到有数据可读或可写；
- 非阻塞：用户线程发起的IO操作会立即返回，如果没有数据可读或可写，则返回一个错误码；
- 多路复用：使用select/poll/epoll等机制，可以让一个线程同时监听多个IO事件，从而提高并发性能。



##### 用户空间和内核态空间

服务器大多都采用Linux系统，这里我们以Linux为例来讲解:

ubuntu和Centos 都是Linux的发行版，发行版可以看成对linux包了一层壳，任何Linux发行版，其系统内核都是Linux。我们的应用都需要通过Linux内核与硬件交互

![1653844970346](D:/资料/该准备面试啦/redis/assets/1653844970346.png)

用户的应用，比如redis，mysql等其实是没有办法去执行访问我们操作系统的硬件的，所以我们可以通过发行版的这个壳子去访问内核，再通过内核去访问计算机硬件

![1653845147190](D:/资料/该准备面试啦/redis/assets/1653845147190.png)

计算机硬件包括，如cpu，内存，网卡等等，内核（通过寻址空间）可以操作硬件的，但是内核需要不同设备的驱动，有了这些驱动之后，内核就可以去对计算机硬件去进行 内存管理，文件系统的管理，进程的管理等等

![1653896065386](D:/资料/该准备面试啦/redis/assets/1653896065386.png)



我们想要用户的应用来访问，计算机就必须要通过对外暴露的一些接口，才能访问到，从而简介的实现对内核的操控，但是内核本身上来说也是一个应用，所以他本身也需要一些内存，cpu等设备资源，用户应用本身也在消耗这些资源，如果不加任何限制，用户去操作随意的去操作我们的资源，就有可能导致一些冲突，甚至有可能导致我们的系统出现无法运行的问题，因此我们需要把用户和**内核隔离开**

进程的寻址空间划分成两部分：**内核空间、用户空间**

**什么是寻址空间呢**？我们的应用程序也好，还是内核空间也好，都是没有办法直接去物理内存的，而是通过分配一些虚拟内存映射到物理内存中，我们的内核和应用程序去访问虚拟内存的时候，就需要一个虚拟地址，这个地址是一个无符号的整数，比如一个32位的操作系统，他的带宽就是32，他的虚拟地址就是2的32次方，也就是说他寻址的范围就是0~2的32次方， 这片寻址空间对应的就是2的32个字节，就是4GB，这个4GB，会有3个GB分给用户空间，会有1GB给内核系统

![1653896377259](D:/资料/该准备面试啦/redis/assets/1653896377259.png)

在linux中，他们权限分成两个等级，0和3，用户空间只能执行受限的命令（Ring3），而且不能直接调用系统资源，必须通过内核提供的接口来访问内核空间可以执行特权命令（Ring0），调用一切系统资源，所以一般情况下，用户的操作是运行在用户空间，而内核运行的数据是在内核空间的，而有的情况下，一个应用程序需要去调用一些特权资源，去调用一些内核空间的操作，所以此时他俩需要在用户态和内核态之间进行切换。

比如：

Linux系统为了提高IO效率，会在用户空间和内核空间都加入缓冲区：

写数据时，要把用户缓冲数据拷贝到内核缓冲区，然后写入设备

读数据时，要从设备读取数据到内核缓冲区，然后拷贝到用户缓冲区

针对这个操作：我们的用户在写读数据时，会去向内核态申请，想要读取内核的数据，而内核数据要去等待驱动程序从硬件上读取数据，当从磁盘上加载到数据之后，内核会将数据写入到内核的缓冲区中，然后再将数据拷贝到用户态的buffer中，然后再返回给应用程序，整体而言，速度慢，就是这个原因，为了加速，我们希望read也好，还是wait for data也最好都不要等待，或者时间尽量的短。

![1653896687354](D:/资料/该准备面试啦/redis/assets/1653896687354.png)

##### 2.2.网络模型-阻塞IO

在《UNIX网络编程》一书中，总结归纳了5种IO模型：

* 阻塞IO（Blocking IO）
* 非阻塞IO（Nonblocking IO）
* IO多路复用（IO Multiplexing）
* 信号驱动IO（Signal Driven IO）
* 异步IO（Asynchronous IO）

应用程序想要去读取数据，他是无法直接去读取磁盘数据的，他需要先到内核里边去等待内核操作硬件拿到数据，这个过程就是1，是需要等待的，等到内核从磁盘上把数据加载出来之后，再把这个数据写给用户的缓存区，这个过程是2，如果是阻塞IO，那么整个过程中，用户从发起读请求开始，一直到读取到数据，都是一个阻塞状态。

![1653897115346](D:/资料/该准备面试啦/redis/assets/1653897115346.png)

具体流程如下图：

用户去读取数据时，会去先发起recvform一个命令，去尝试从内核上加载数据，如果内核没有数据，那么用户就会等待，此时内核会去从硬件上读取数据，内核读取数据之后，会把数据拷贝到用户态，并且返回ok，整个过程，都是阻塞等待的，这就是阻塞IO

总结如下：

顾名思义，阻塞IO就是两个阶段都必须阻塞等待：

**阶段一：**

- 用户进程尝试读取数据（比如网卡数据）
- 此时数据尚未到达，内核需要等待数据
- 此时用户进程也处于阻塞状态

阶段二：

* 数据到达并拷贝到内核缓冲区，代表已就绪
* 将内核数据拷贝到用户缓冲区
* 拷贝过程中，用户进程依然阻塞等待
* 拷贝完成，用户进程解除阻塞，处理数据

可以看到，阻塞IO模型中，用户进程在两个阶段都是阻塞状态。



![1653897270074](D:/资料/该准备面试啦/redis/assets/1653897270074.png)

##### 2.3 网络模型-非阻塞IO

顾名思义，非阻塞IO的recvfrom操作会立即返回结果而不是阻塞用户进程。

阶段一：

* 用户进程尝试读取数据（比如网卡数据）
* 此时数据尚未到达，内核需要等待数据
* 返回异常给用户进程
* 用户进程拿到error后，再次尝试读取
* 循环往复，直到数据就绪

阶段二：

* 将内核数据拷贝到用户缓冲区
* 拷贝过程中，用户进程依然阻塞等待
* 拷贝完成，用户进程解除阻塞，处理数据
* 可以看到，**非阻塞IO模型中，用户进程在第一个阶段是非阻塞，第二个阶段是阻塞状态。虽然是非阻塞，但性能并没有得到提高。而且忙等机制会导致CPU空转，CPU使用率暴增。**



![1653897490116](D:/资料/该准备面试啦/redis/assets/1653897490116.png)

##### 2.4 网络模型-IO多路复用

无论是阻塞IO还是非阻塞IO，用户应用在一阶段都需要调用recvfrom来获取数据，差别在于无数据时的处理方案：

- 如果调用recvfrom时，**恰好没有数据**，阻塞IO会使CPU阻塞，非阻塞IO使CPU空转，都不能充分发挥CPU的作用。

- 如果调用recvfrom时，**恰好有数据**，则用户进程可以直接进入第二阶段，读取并处理数据

所以怎么看起来以上两种方式性能都不好

而在单线程情况下，只能依次处理IO事件，如果正在处理的IO事件恰好未就绪（数据不可读或不可写），线程就会被阻塞，所有IO事件都必须等待，性能自然会很差。

就比如服务员给顾客点餐，**分两步**：

* 顾客思考要吃什么（等待数据就绪）
* 顾客想好了，开始点餐（读取数据）

要提高效率有几种办法？

方案一：增加更多服务员（多线程）
方案二：不排队，谁想好了吃什么（数据就绪了），服务员就给谁点餐（用户应用就去读取数据）

**那么问题来了：用户进程如何知道内核中数据是否就绪呢？**

所以接下来就需要详细的来解决**多路复用模型**是如何知道到底怎么知道内核数据是否就绪的问题了

这个问题的解决依赖于提出的文件描述符（File Descriptor）：简称FD，是一个从0 开始的无符号整数，**用来关联Linux中的一个文件。在Linux中，一切皆文件，例如常规文件、视频、硬件设备等，当然也包括网络套接字（Socket）。**

通过FD，我们的**网络模型可以利用一个线程监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。**

阶段一：

* 用户进程调用select，指定要监听的FD集合
* 核监听FD对应的多个socket
* 任意一个或多个socket数据就绪则返回readable
* 此过程中用户进程阻塞

阶段二：

* 用户进程找到就绪的socket
* 依次调用recvfrom读取数据
* 内核将数据拷贝到用户空间
* 用户进程处理数据

当用户去读取数据的时候，不再去直接调用recvfrom了，而是调用select的函数，select函数会将需要监听的数据交给内核，由内核去检查这些数据是否就绪了，如果说这个数据就绪了，就会通知应用程序数据就绪，然后来读取数据，再从内核中把数据拷贝给用户态，完成数据处理，如果N多个FD一个都没处理完，此时就进行等待。

用IO复用模式，可以确保去读数据的时候，数据是一定存在的，他的效率比原来的阻塞IO和非阻塞IO性能都要高



![1653898691736](D:/资料/该准备面试啦/redis/assets/1653898691736.png)



IO多路复用是利用**单个线程来同时监听多个FD，并在某个FD可读、可写时得到通知**，从而避免无效的等待，充分利用CPU资源。不过监听FD的方式、通知的方式又有多种实现，常见的有：

- select
- poll
- epoll



**差异：**

- 其中select和pool相当于是当被监听的数据准备好之后，他会把你监听的FD整个数据都发给你，你需要到整个FD中去找，哪些是处理好了的，需要通过遍历的方式，所以性能也并不是那么好

- 而epoll，则相当于内核准备好了之后，他会把准备好的数据，直接发给你，咱们就省去了遍历的动作。




##### 2.5 网络模型-IO多路复用-select方式

select是Linux最早是由的I/O多路复用技术：

简单说，就是我们把需要处理的数据封装成FD，然后在用户态时创建一个fd的集合（这个集合的大小是要监听的那个FD的最大值+1，但是大小整体是有限制的 ），这个集合的长度大小是有限制的，同时在这个集合中，标明出来我们要控制哪些数据，

比如要监听的数据，是1,2,5三个数据，此时会执行select函数，然后将整个fd发给内核态，内核态会去遍历用户态传递过来的数据，如果发现这里边都数据都没有就绪，就休眠，直到有数据准备好时，就会被唤醒，唤醒之后，再次遍历一遍，看看谁准备好了，然后再将处理掉没有准备好的数据，最后再将这个FD集合写回到用户态中去，此时用户态就知道了，奥，有人准备好了，但是对于用户态而言，并不知道谁处理好了，所以用户态也需要去进行遍历，然后找到对应准备好数据的节点，再去发起读请求，我们会发现，这种模式下他虽然比阻塞IO和非阻塞IO好，但是依然有些麻烦的事情， 比如说频繁的传递fd集合，频繁的去遍历FD等问题

![1653900022580](D:/资料/该准备面试啦/redis/assets/1653900022580.png)



**select存在的问题：**

- 需要将整个fd_set从用户空间拷贝到内核空间，select结束还要再次拷贝会用户空间。
- select无法得知具体是哪个fd就绪，需要遍历整个fd_set
- fd_set监听的fd数量不能超过1024



##### 2.6 网络模型-IO多路复用模型-poll模式

poll模式对select模式做了简单改进，但性能提升不明显，部分关键代码如下：

IO流程：

* 创建pollfd数组，向其中添加关注的fd信息，数组大小自定义
* 调用poll函数，将pollfd数组拷贝到内核空间，转链表存储，无上限
* 内核遍历fd，判断是否就绪
* 数据就绪或超时后，拷贝pollfd数组到用户空间，返回就绪fd数量n
* 用户进程判断n是否大于0,大于0则遍历pollfd数组，找到就绪的fd

**与select对比：**

* select模式中的fd_set大小固定为1024，而pollfd在内核中采用链表，理论上无上限
* 监听FD越多，每次遍历消耗时间也越久，性能反而会下降。

![1653900721427](D:/资料/该准备面试啦/redis/assets/1653900721427.png)

##### 2.7 网络模型-IO多路复用模型-epoll函数

epoll模式是对select和poll的改进，它提供了**三个函数：**

第一个是：**eventpoll的函数**，他内部包含两个东西

一个是：

**1、红黑树-> 记录的事要监听的FD**

**2、一个是链表->一个链表，记录的是就绪的FD**

![image-20221206142829472](C:\Users\关于废人张\AppData\Roaming\Typora\typora-user-images\image-20221206142829472.png)

2、紧接着调用**epoll_ctl**操作，将要**监听的数据添加到红黑树上去**，并且给**每个fd设置一个监听函数**，这个函数会在**fd数据就绪时触发**，就是准备好了，现在就把fd把数据添加到**list_head**中去

3、调用**epoll_wait**函数

就去等待，在用户态创建一个空的events数组，当就绪之后，我们的回调函数会把数据添加到list_head中去，当调用这个函数的时候，会去检查list_head，当然这个过程需要参考配置的等待时间，可以等一定时间，也可以一直等， 如果在此过程中，检查到了list_head中有数据会将数据添加到链表中，此时将数据放入到events数组中，并且返回对应的操作的数量，用户态的此时收到响应后，从events中拿到对应准备好的数据的节点，再去调用方法去拿数据。

![image-20221206143036586](C:\Users\关于废人张\AppData\Roaming\Typora\typora-user-images\image-20221206143036586.png)



![image-20221206143100052](C:\Users\关于废人张\AppData\Roaming\Typora\typora-user-images\image-20221206143100052.png)



![image-20221206143151442](C:\Users\关于废人张\AppData\Roaming\Typora\typora-user-images\image-20221206143151442.png)



![image-20221206143211117](C:\Users\关于废人张\AppData\Roaming\Typora\typora-user-images\image-20221206143211117.png)







小总结：

select模式存在的三个问题：

* 能监听的FD最大不超过1024
* 每次select都需要把所有要监听的FD都拷贝到内核空间
* 每次都要遍历所有FD来判断就绪状态

poll模式的问题：

* poll利用链表解决了select中监听FD上限的问题，但依然要遍历所有FD，如果监听较多，性能会下降

**epoll模式中如何解决这些问题的？**

* 基于epoll实例中的**红黑树**保存要监听的FD，理论上无上限，而且增删改查效率都非常高
* 每个FD只需要执行一次epoll_ctl添加到红黑树，以后每次epol_wait无需传递任何参数，无需重复拷贝FD到内核空间
* 利用ep_poll_callback机制来监听FD状态，无需遍历所有FD，因此性能不会随监听的FD数量增多而下降。





##### 2.8、网络模型-epoll中的ET和LT

当FD有数据可读时，我们调用epoll_wait（或者select、poll）可以得到通知。但是事件通知的模式有两种：

* LevelTriggered：简称LT，也叫做水平触发。只要某个FD中有数据可读，每次调用epoll_wait都会得到通知。当FD有数据可读时，会冲恢复通知多次，知道数据处理完成，是epoll默认的模式
* EdgeTriggered：简称ET，也叫做边沿触发。只有在某个FD有状态变化时，调用epoll_wait才会被通知。当G+FD有数据可读时，只会被通知一次，不管数据是否处理完成。

举个栗子：

1. 假设一个客户端socket对应的FD已经注册到了epoll实例中
2. 客户端socket发送了2kb的数据
3. 服务端调用epoll_wait，得到通知说FD就绪
4. 服务端从FD读取了1kb数据
5. 回到步骤3（再次调用epoll_wait，形成循环）



![image-20221206144027039](C:\Users\关于废人张\AppData\Roaming\Typora\typora-user-images\image-20221206144027039.png)



![image-20221206144045285](C:\Users\关于废人张\AppData\Roaming\Typora\typora-user-images\image-20221206144045285.png)



![image-20221206144055185](C:\Users\关于废人张\AppData\Roaming\Typora\typora-user-images\image-20221206144055185.png)



LT存在的问题：

- 惊群现象
- 





结论

如果我们采用LT模式，因为FD中仍有1kb数据，则第⑤步依然会返回结果，并且得到通知
如果我们采用ET模式，因为第③步已经消费了FD可读事件，第⑤步FD状态没有变化，因此epoll_wait不会返回，数据无法读取，客户端响应超时。

##### 2.9 网络模型-基于epoll的服务器端流程

我们来梳理一下这张图

![1653902845082](D:/资料/该准备面试啦/redis/assets/1653902845082.png)



服务器启动以后，服务端会去调用epoll_create，创建一个epoll实例，epoll实例中包含两个数据

1、红黑树（为空）：rb_root 用来去记录需要被监听的FD

2、链表（为空）：list_head，用来存放已经就绪的FD

创建好了之后，会去调用epoll_ctl函数，此函数会会将需要监听的数据添加到rb_root中去，并且对当前这些存在于红黑树的节点设置回调函数，当这些被监听的数据一旦准备完成，就会被调用，而调用的结果就是将红黑树的fd添加到list_head中去(但是此时并没有完成)

3、当第二步完成后，就会调用epoll_wait函数，这个函数会去校验是否有数据准备完毕（因为数据一旦准备就绪，就会被回调函数添加到list_head中），在等待了一段时间后(可以进行配置)，如果等够了超时时间，则返回没有数据，如果有，则进一步判断当前是什么事件，如果是建立连接时间，则调用accept() 接受客户端socket，拿到建立连接的socket，然后建立起来连接，如果是其他事件，则把数据进行写出



##### 3.0 、网络模型-信号驱动IO

信号驱动IO是与内核建立SIGIO的信号关联并设置回调，当内核有FD就绪时，会发出SIGIO信号通知用户，期间用户应用可以执行其它业务，无需阻塞等待。



![1653911776583](D:/资料/该准备面试啦/redis/assets/1653911776583.png)



阶段一：

* 用户进程调用sigaction，注册信号处理函数
* 内核返回成功，开始监听FD
* 用户进程不阻塞等待，可以执行其它业务
* 当内核数据就绪后，回调用户进程的SIGIO处理函数

阶段二：

* 收到SIGIO回调信号
* 调用recvfrom，读取
* 内核将数据拷贝到用户空间
* 用户进程处理数据



**缺点：**

- 当有大量IO操作时，信号较多，SIGIO处理函数不能及时处理可能导致信号队列溢出
- 而且内核空间与用户空间的频繁信号交互性能也较低。

##### 3.0.1 异步IO

这种方式，不仅仅是用户态在试图读取数据后，不阻塞，而且当内核的数据准备完成后，也不会阻塞

他会由内核将所有数据处理完成后，由内核将数据写入到用户态中，然后才算完成，所以性能极高，不会有任何阻塞，全部都由内核完成，可以看到，异步IO模型中，用户进程在两个阶段都是非阻塞状态。

![1653911877542](D:/资料/该准备面试啦/redis/assets/1653911877542.png)



存在问题：在高并发情况下，会导致处理数据的并发线程过多，导致内存占用过多，从而导致异常



##### 3.0.2 全部IO对比（同步和异步）

只需要考虑第二阶段

最后用一幅图，来说明他们之间的区别

![1653912219712](D:/资料/该准备面试啦/redis/assets/1653912219712.png)

### 



